{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c6be127-c0a2-4c22-a429-1f431081427f",
   "metadata": {},
   "source": [
    "# Tokenization :(\n",
    "\n",
    "Tokenization is at the heart of much weirdness of LLMs. Do not brush it off.\n",
    "\n",
    "- Why can't LLM spell words? **Tokenization**.\n",
    "- Why can't LLM do super simple string processing tasks like reversing a string? **Tokenization**.\n",
    "- Why is LLM worse at non-English languages (e.g. Japanese)? **Tokenization**.\n",
    "- Why is LLM bad at simple arithmetic? **Tokenization**.\n",
    "- Why did GPT-2 have more than necessary trouble coding in Python? **Tokenization**.\n",
    "- Why did my LLM abruptly halt when it sees the string \"<|endoftext|>\"? **Tokenization**.\n",
    "- What is this weird warning I get about a \"trailing whitespace\"? **Tokenization**.\n",
    "- Why the LLM break if I ask it about \"SolidGoldMagikarp\"? **Tokenization**.\n",
    "- Why should I prefer to use YAML over JSON with LLMs? **Tokenization**.\n",
    "- Why is LLM not actually end-to-end language modeling? **Tokenization**.\n",
    "- What is the real root of suffering? **Tokenization**.\n",
    "\n",
    "---\n",
    "\n",
    "Good tokenization web app: [https://tiktokenizer.vercel.app](https://tiktokenizer.vercel.app)\n",
    "\n",
    "Example string:\n",
    "\n",
    "```\n",
    "Tokenization is at the heart of much weirdness of LLMs. Do not brush it off.\n",
    "\n",
    "127 + 677 = 804\n",
    "1275 + 6773 = 8041\n",
    "\n",
    "Egg.\n",
    "I have an Egg.\n",
    "egg.\n",
    "EGG.\n",
    "\n",
    "ÎßåÎÇòÏÑú Î∞òÍ∞ÄÏõåÏöî. Ï†ÄÎäî OpenAIÏóêÏÑú Í∞úÎ∞úÌïú ÎåÄÍ∑úÎ™® Ïñ∏Ïñ¥ Î™®Îç∏Ïù∏ ChatGPTÏûÖÎãàÎã§. Í∂ÅÍ∏àÌïú Í≤ÉÏù¥ ÏûàÏúºÏãúÎ©¥ Î¨¥ÏóáÏù¥Îì† Î¨ºÏñ¥Î≥¥ÏÑ∏Ïöî.\n",
    "\n",
    "for i in range(1, 101):\n",
    "    if i % 3 == 0 and i % 5 == 0:\n",
    "        print(\"FizzBuzz\")\n",
    "    elif i % 3 == 0:\n",
    "        print(\"Fizz\")\n",
    "    elif i % 5 == 0:\n",
    "        print(\"Buzz\")\n",
    "    else:\n",
    "        print(i)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "Much glory awaits someone who can delete the need for tokenization. But meanwhile, let's learn about it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2feb9f5b-4631-4d8b-bf73-0864f3de7b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[48152, 44032, 50892, 50836]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ord(x) for x in \"Î∞òÍ∞ÄÏõåÏöî\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c361c7cf-4cc1-4b23-bc17-7ecabc0079c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[104,\n",
       " 101,\n",
       " 108,\n",
       " 108,\n",
       " 111,\n",
       " 32,\n",
       " 105,\n",
       " 32,\n",
       " 97,\n",
       " 109,\n",
       " 32,\n",
       " 102,\n",
       " 114,\n",
       " 111,\n",
       " 109,\n",
       " 32,\n",
       " 103,\n",
       " 97,\n",
       " 110,\n",
       " 103,\n",
       " 116,\n",
       " 111,\n",
       " 107]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(\"hello i am from gangtok\".encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a74b5064-2bcc-4511-aa0d-868fae7644ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "Hi everyone, üòótoday we are going to look at Tokenization in Large Language Models (LLMs). Sadly, tokenization is a relatively complex and gnarly component of the state of the art LLMs, but it is necessary to understand in some detail because a lot of the shortcomings of LLMs that may be attributed to the neural network or otherwise appear mysterious actually trace back to tokenization.\n",
      "Length of text 388\n",
      "-------\n",
      "[72, 105, 32, 101, 118, 101, 114, 121, 111, 110, 101, 44, 32, 240, 159, 152, 151, 116, 111, 100, 97, 121, 32, 119, 101, 32, 97, 114, 101, 32, 103, 111, 105, 110, 103, 32, 116, 111, 32, 108, 111, 111, 107, 32, 97, 116, 32, 84, 111, 107, 101, 110, 105, 122, 97, 116, 105, 111, 110, 32, 105, 110, 32, 76, 97, 114, 103, 101, 32, 76, 97, 110, 103, 117, 97, 103, 101, 32, 77, 111, 100, 101, 108, 115, 32, 40, 76, 76, 77, 115, 41, 46, 32, 83, 97, 100, 108, 121, 44, 32, 116, 111, 107, 101, 110, 105, 122, 97, 116, 105, 111, 110, 32, 105, 115, 32, 97, 32, 114, 101, 108, 97, 116, 105, 118, 101, 108, 121, 32, 99, 111, 109, 112, 108, 101, 120, 32, 97, 110, 100, 32, 103, 110, 97, 114, 108, 121, 32, 99, 111, 109, 112, 111, 110, 101, 110, 116, 32, 111, 102, 32, 116, 104, 101, 32, 115, 116, 97, 116, 101, 32, 111, 102, 32, 116, 104, 101, 32, 97, 114, 116, 32, 76, 76, 77, 115, 44, 32, 98, 117, 116, 32, 105, 116, 32, 105, 115, 32, 110, 101, 99, 101, 115, 115, 97, 114, 121, 32, 116, 111, 32, 117, 110, 100, 101, 114, 115, 116, 97, 110, 100, 32, 105, 110, 32, 115, 111, 109, 101, 32, 100, 101, 116, 97, 105, 108, 32, 98, 101, 99, 97, 117, 115, 101, 32, 97, 32, 108, 111, 116, 32, 111, 102, 32, 116, 104, 101, 32, 115, 104, 111, 114, 116, 99, 111, 109, 105, 110, 103, 115, 32, 111, 102, 32, 76, 76, 77, 115, 32, 116, 104, 97, 116, 32, 109, 97, 121, 32, 98, 101, 32, 97, 116, 116, 114, 105, 98, 117, 116, 101, 100, 32, 116, 111, 32, 116, 104, 101, 32, 110, 101, 117, 114, 97, 108, 32, 110, 101, 116, 119, 111, 114, 107, 32, 111, 114, 32, 111, 116, 104, 101, 114, 119, 105, 115, 101, 32, 97, 112, 112, 101, 97, 114, 32, 109, 121, 115, 116, 101, 114, 105, 111, 117, 115, 32, 97, 99, 116, 117, 97, 108, 108, 121, 32, 116, 114, 97, 99, 101, 32, 98, 97, 99, 107, 32, 116, 111, 32, 116, 111, 107, 101, 110, 105, 122, 97, 116, 105, 111, 110, 46]\n",
      "length of tokens 391\n"
     ]
    }
   ],
   "source": [
    "text = \"Hi everyone, üòótoday we are going to look at Tokenization in Large Language Models (LLMs). Sadly, tokenization is a relatively complex and gnarly component of the state of the art LLMs, but it is necessary to understand in some detail because a lot of the shortcomings of LLMs that may be attributed to the neural network or otherwise appear mysterious actually trace back to tokenization.\"\n",
    "tokens = text.encode(\"utf-8\")\n",
    "tokens = list(map(int, tokens))\n",
    "print('------')\n",
    "print(text)\n",
    "print(\"Length of text\" , len(text))\n",
    "print('-------')\n",
    "print(tokens)\n",
    "print(\"length of tokens\", len(tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9784785-b48d-4c73-abe5-5e8e5bc2fd27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(14, (101, 32)), (12, (32, 116)), (9, (32, 97)), (8, (97, 116)), (7, (116, 111)), (7, (116, 32)), (6, (121, 32)), (6, (116, 104)), (6, (115, 32)), (6, (97, 114)), (6, (32, 111)), (5, (111, 110)), (5, (110, 101)), (5, (104, 101)), (5, (32, 105)), (4, (116, 105)), (4, (111, 109)), (4, (111, 107)), (4, (111, 102)), (4, (111, 32)), (4, (110, 32)), (4, (108, 121)), (4, (105, 111)), (4, (105, 110)), (4, (102, 32)), (4, (101, 114)), (4, (101, 110)), (4, (32, 98)), (4, (32, 76)), (3, (122, 97)), (3, (116, 101)), (3, (116, 97)), (3, (115, 116)), (3, (111, 114)), (3, (110, 105)), (3, (110, 103)), (3, (110, 100)), (3, (107, 101)), (3, (107, 32)), (3, (105, 122)), (3, (105, 115)), (3, (101, 108)), (3, (100, 101)), (3, (100, 32)), (3, (99, 111)), (3, (97, 110)), (3, (97, 99)), (3, (77, 115)), (3, (76, 77)), (3, (76, 76)), (3, (44, 32)), (3, (32, 115)), (3, (32, 110)), (2, (118, 101)), (2, (117, 116)), (2, (117, 115)), (2, (117, 97)), (2, (116, 114)), (2, (115, 101)), (2, (114, 121)), (2, (114, 116)), (2, (114, 105)), (2, (114, 101)), (2, (114, 97)), (2, (114, 32)), (2, (111, 116)), (2, (111, 100)), (2, (109, 112)), (2, (108, 111)), (2, (108, 32)), (2, (103, 101)), (2, (101, 116)), (2, (101, 99)), (2, (99, 101)), (2, (98, 117)), (2, (98, 101)), (2, (97, 121)), (2, (97, 108)), (2, (97, 32)), (2, (76, 97)), (2, (32, 109)), (2, (32, 108)), (2, (32, 103)), (2, (32, 99)), (1, (240, 159)), (1, (159, 152)), (1, (152, 151)), (1, (151, 116)), (1, (121, 115)), (1, (121, 111)), (1, (121, 44)), (1, (120, 32)), (1, (119, 111)), (1, (119, 105)), (1, (119, 101)), (1, (117, 114)), (1, (117, 110)), (1, (116, 119)), (1, (116, 117)), (1, (116, 116)), (1, (116, 99)), (1, (115, 115)), (1, (115, 111)), (1, (115, 104)), (1, (115, 97)), (1, (115, 44)), (1, (115, 41)), (1, (114, 119)), (1, (114, 115)), (1, (114, 108)), (1, (114, 107)), (1, (114, 103)), (1, (112, 112)), (1, (112, 111)), (1, (112, 108)), (1, (112, 101)), (1, (111, 117)), (1, (111, 111)), (1, (111, 105)), (1, (110, 116)), (1, (110, 97)), (1, (110, 46)), (1, (109, 121)), (1, (109, 105)), (1, (109, 101)), (1, (109, 97)), (1, (108, 115)), (1, (108, 108)), (1, (108, 101)), (1, (108, 97)), (1, (105, 118)), (1, (105, 116)), (1, (105, 108)), (1, (105, 98)), (1, (105, 32)), (1, (104, 111)), (1, (104, 97)), (1, (103, 117)), (1, (103, 115)), (1, (103, 111)), (1, (103, 110)), (1, (103, 32)), (1, (101, 120)), (1, (101, 118)), (1, (101, 117)), (1, (101, 115)), (1, (101, 100)), (1, (101, 97)), (1, (101, 44)), (1, (100, 108)), (1, (100, 97)), (1, (99, 116)), (1, (99, 107)), (1, (99, 97)), (1, (98, 97)), (1, (97, 117)), (1, (97, 112)), (1, (97, 105)), (1, (97, 103)), (1, (97, 100)), (1, (84, 111)), (1, (83, 97)), (1, (77, 111)), (1, (72, 105)), (1, (46, 32)), (1, (41, 46)), (1, (40, 76)), (1, (32, 240)), (1, (32, 119)), (1, (32, 117)), (1, (32, 114)), (1, (32, 101)), (1, (32, 100)), (1, (32, 84)), (1, (32, 83)), (1, (32, 77)), (1, (32, 40))]\n"
     ]
    }
   ],
   "source": [
    "def get_stats(ids):\n",
    "    counts = {}\n",
    "    for pair in zip(ids, ids[1:]):\n",
    "        counts[pair] = counts.get(pair, 0) + 1\n",
    "    return counts\n",
    "\n",
    "stats = get_stats(tokens)\n",
    "# print(stats)\n",
    "print(sorted(((v, k) for k,v in stats.items()), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d47140ca-d797-43f0-b1ed-9337450ff7ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' ', 't')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(32) , chr(116)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e221916b-b18d-492d-96b4-ac64d37abdc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_pair = max(stats, key=stats.get)\n",
    "top_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a9bd4a0-4a38-4cfd-8522-5de110f166df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[72, 105, 32, 101, 118, 101, 114, 121, 111, 110, 101, 44, 32, 240, 159, 152, 151, 116, 111, 100, 97, 121, 32, 119, 256, 97, 114, 256, 103, 111, 105, 110, 103, 32, 116, 111, 32, 108, 111, 111, 107, 32, 97, 116, 32, 84, 111, 107, 101, 110, 105, 122, 97, 116, 105, 111, 110, 32, 105, 110, 32, 76, 97, 114, 103, 256, 76, 97, 110, 103, 117, 97, 103, 256, 77, 111, 100, 101, 108, 115, 32, 40, 76, 76, 77, 115, 41, 46, 32, 83, 97, 100, 108, 121, 44, 32, 116, 111, 107, 101, 110, 105, 122, 97, 116, 105, 111, 110, 32, 105, 115, 32, 97, 32, 114, 101, 108, 97, 116, 105, 118, 101, 108, 121, 32, 99, 111, 109, 112, 108, 101, 120, 32, 97, 110, 100, 32, 103, 110, 97, 114, 108, 121, 32, 99, 111, 109, 112, 111, 110, 101, 110, 116, 32, 111, 102, 32, 116, 104, 256, 115, 116, 97, 116, 256, 111, 102, 32, 116, 104, 256, 97, 114, 116, 32, 76, 76, 77, 115, 44, 32, 98, 117, 116, 32, 105, 116, 32, 105, 115, 32, 110, 101, 99, 101, 115, 115, 97, 114, 121, 32, 116, 111, 32, 117, 110, 100, 101, 114, 115, 116, 97, 110, 100, 32, 105, 110, 32, 115, 111, 109, 256, 100, 101, 116, 97, 105, 108, 32, 98, 101, 99, 97, 117, 115, 256, 97, 32, 108, 111, 116, 32, 111, 102, 32, 116, 104, 256, 115, 104, 111, 114, 116, 99, 111, 109, 105, 110, 103, 115, 32, 111, 102, 32, 76, 76, 77, 115, 32, 116, 104, 97, 116, 32, 109, 97, 121, 32, 98, 256, 97, 116, 116, 114, 105, 98, 117, 116, 101, 100, 32, 116, 111, 32, 116, 104, 256, 110, 101, 117, 114, 97, 108, 32, 110, 101, 116, 119, 111, 114, 107, 32, 111, 114, 32, 111, 116, 104, 101, 114, 119, 105, 115, 256, 97, 112, 112, 101, 97, 114, 32, 109, 121, 115, 116, 101, 114, 105, 111, 117, 115, 32, 97, 99, 116, 117, 97, 108, 108, 121, 32, 116, 114, 97, 99, 256, 98, 97, 99, 107, 32, 116, 111, 32, 116, 111, 107, 101, 110, 105, 122, 97, 116, 105, 111, 110, 46]\n",
      "length: 377\n"
     ]
    }
   ],
   "source": [
    "def merge(ids, pair, idx):\n",
    "    newids = []\n",
    "    i = 0\n",
    "    while i < len(ids):\n",
    "        if i < len(ids) - 1 and ids[i] == pair[0] and ids[i+1] == pair[1]:\n",
    "            newids.append(idx)\n",
    "            i += 2\n",
    "        else:\n",
    "            newids.append(ids[i])\n",
    "            i += 1\n",
    "    return newids\n",
    "\n",
    "# print(merge([5, 6, 6, 7 , 9, 1], (6,7), 99))\n",
    "tokens2 = merge(tokens, top_pair, 256)\n",
    "print(tokens2)\n",
    "print(\"length:\" , len(tokens2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "786ef41c-d7b4-4049-a6aa-f8937d3465dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[109, 32, 110, 111, 116, 32, 101, 110, 116, 105, 114, 101, 108, 121, 32, 115, 117, 114, 101, 32, 119, 104, 121, 32, 116, 104, 101, 32, 119, 111, 114, 100, 32, 226, 128, 152, 115, 108, 111, 112, 226, 128, 153, 32, 98, 101, 99, 97, 109, 101, 32, 115, 121, 110, 111, 110, 121, 109, 111, 117, 115, 32, 119, 105, 116, 104, 32, 116, 104, 101, 32, 99, 117, 114, 114, 101, 110, 116, 32, 119, 97, 118, 101, 32, 111, 102, 32, 65, 73, 44, 32, 98, 117, 116, 32, 73, 226, 128, 153, 109, 32, 115, 117, 114, 101, 32, 116, 104, 97, 116, 32, 101, 116, 121, 109, 111, 108, 111, 103, 105, 115, 116, 115, 32, 40, 110, 111, 119, 44, 32, 111, 114, 32, 105, 110, 32, 116, 104, 101, 32, 100, 105, 115, 116, 97, 110, 116, 32, 102, 117, 116, 117, 114, 101, 41, 32, 119, 105, 108, 108, 32, 112, 114, 111, 100, 117, 99, 101, 32, 102, 97, 115, 99, 105, 110, 97, 116, 105, 110, 103, 32, 114, 101, 115, 101, 97, 114, 99, 104, 32, 111, 110, 32, 116, 104, 105, 115, 32, 115, 117, 98, 106, 101, 99, 116, 46, 32, 83, 108, 111, 112, 58, 32, 105, 116, 32, 99, 111, 110, 110, 111, 116, 101, 115, 32, 98, 111, 116, 104, 32, 116, 104, 101, 32, 98, 108, 97, 110, 100, 44, 32, 102, 111, 114, 109, 108, 101, 115, 115, 110, 101, 115, 115, 32, 111, 102, 32, 65, 73, 45, 99, 111, 110, 116, 101, 110, 116, 32, 40, 97, 114, 116, 32, 116, 104, 97, 116, 32, 108, 111, 111, 107, 115, 44, 32, 115, 105, 109, 117, 108, 116, 97, 110, 101, 111, 117, 115, 108, 121, 44, 32, 108, 105, 107, 101, 32, 97, 108, 108, 32, 97, 114, 116, 32, 97, 110, 100, 32, 110, 111, 32, 97, 114, 116, 41, 32, 97, 110, 100, 32, 97, 108, 115, 111, 32, 104, 97, 115, 32, 116, 104, 101, 32, 68, 105, 99, 107, 101, 110, 115, 105, 97, 110, 32, 115, 101, 110, 115, 101, 32, 111, 102, 32, 98, 101, 105, 110, 103, 32, 115, 101, 114, 118, 101, 32, 103, 114, 101, 97, 116, 32, 108, 97, 115, 104, 105, 110, 103, 115, 32, 111, 102, 32, 103, 114, 117, 101, 108, 44, 32, 97, 108, 109, 111, 115, 116, 32, 119, 105, 116, 104, 111, 117, 116, 32, 99, 111, 110, 115, 101, 110, 116, 46, 32, 226, 128, 156, 68, 111, 32, 73, 32, 117, 110, 100, 101, 114, 115, 116, 97, 110, 100, 32, 116, 104, 97, 116, 32, 104, 101, 32, 97, 115, 107, 101, 100, 32, 102, 111, 114, 32, 109, 111, 114, 101, 44, 32, 97, 102, 116, 101, 114, 32, 104, 101, 32, 104, 97, 100, 32, 101, 97, 116, 101, 110, 32, 116, 104, 101, 32, 115, 117, 112, 112, 101, 114, 32, 97, 108, 108, 111, 116, 116, 101, 100, 32, 98, 121, 32, 116, 104, 101, 32, 100, 105, 101, 116, 97, 114, 121, 63, 226, 128, 157, 32, 77, 114, 32, 76, 105, 109, 98, 107, 105, 110, 115, 32, 105, 110, 113, 117, 105, 114, 101, 115, 44, 32, 105, 110, 99, 114, 101, 100, 117, 108, 111, 117, 115, 108, 121, 44, 32, 97, 102, 116, 101, 114, 32, 79, 108, 105, 118, 101, 114, 32, 84, 119, 105, 115, 116, 32, 100, 101, 109, 97, 110, 100, 115, 32, 104, 105, 115, 32, 101, 120, 116, 114, 97, 32, 115, 108, 111, 112, 46, 32, 226, 128, 156, 84, 104, 97, 116, 32, 98, 111, 121, 32, 119, 105, 108, 108, 32, 98, 101, 32, 104, 117, 110, 103, 33, 226, 128, 157, 10, 10, 73, 116, 226, 128, 153, 115, 32, 97, 110, 32, 97, 112, 116, 32, 119, 111, 114, 100, 44, 32, 98, 117, 116, 32, 73, 32, 104, 97, 118, 101, 32, 98, 101, 101, 110, 32, 116, 104, 105, 110, 107, 105, 110, 103, 32, 111, 102, 32, 108, 97, 116, 101, 32, 97, 98, 111, 117, 116, 32, 97, 110, 111, 116, 104, 101, 114, 32, 97, 32, 100, 105, 102, 102, 101, 114, 101, 110, 116, 32, 100, 101, 115, 99, 114, 105, 112, 116, 111, 114, 32, 102, 111, 114, 32, 65, 73, 32, 99, 111, 110, 116, 101, 110, 116, 58, 32, 116, 104, 101, 32, 84, 115, 117, 110, 97, 109, 65, 73, 46, 10, 10, 73, 32, 115, 112, 101, 110, 116, 32, 115, 111, 109, 101, 32, 111, 102, 32, 116, 104, 105, 115, 32, 119, 101, 101, 107, 32, 119, 111, 114, 107, 105, 110, 103, 32, 40, 105, 110, 32, 109, 121, 32, 48, 57, 58, 48, 48, 226, 128, 147, 49, 55, 58, 48, 48, 32, 99, 97, 112, 97, 99, 105, 116, 121, 41, 32, 97, 115, 32, 97, 32, 112, 114, 111, 100, 117, 99, 101, 114, 32, 111, 110, 32, 97, 32, 112, 111, 100, 99, 97, 115, 116, 32, 108, 111, 111, 107, 105, 110, 103, 32, 97, 116, 32, 116, 104, 101, 32, 69, 109, 112, 108, 111, 121, 101, 101, 32, 82, 105, 103, 104, 116, 115, 32, 66, 105, 108, 108, 44, 32, 119, 104, 105, 99, 104, 32, 115, 104, 111, 117, 108, 100, 32, 115, 104, 111, 114, 116, 108, 121, 32, 98, 101, 99, 111, 109, 101, 32, 108, 97, 119, 32, 105, 110, 32, 116, 104, 101, 32, 85, 75, 46, 32, 73, 116, 32, 105, 115, 32, 97, 32, 115, 112, 114, 97, 119, 108, 105, 110, 103, 32, 112, 105, 101, 99, 101, 32, 111, 102, 32, 108, 101, 103, 105, 115, 108, 97, 116, 105, 111, 110, 32, 99, 111, 118, 101, 114, 105, 110, 103, 32, 101, 118, 101, 114, 121, 116, 104, 105, 110, 103, 32, 102, 114, 111, 109, 32, 68, 97, 121, 32, 79, 110, 101, 32, 114, 105, 103, 104, 116, 115, 32, 116, 111, 32, 226, 128, 152, 102, 105, 114, 101, 32, 97, 110, 100, 32, 114, 101, 104, 105, 114, 101, 226, 128, 153, 32, 112, 114, 97, 99, 116, 105, 99, 101, 115, 44, 32, 97, 110, 100, 44, 32, 119, 104, 105, 108, 101, 32, 105, 110, 116, 101, 114, 101, 115, 116, 105, 110, 103, 44, 32, 105, 115, 32, 110, 111, 116, 32, 116, 104, 101, 32, 115, 117, 98, 106, 101, 99, 116, 32, 111, 102, 32, 116, 104, 105, 115, 32, 110, 101, 119, 115, 108, 101, 116, 116, 101, 114, 46, 32, 79, 110, 32, 116, 104, 101, 32, 101, 112, 105, 115, 111, 100, 101, 32, 119, 101, 32, 109, 97, 100, 101, 44, 32, 97, 32, 108, 101, 97, 100, 105, 110, 103, 32, 101, 109, 112, 108, 111, 121, 109, 101, 110, 116, 32, 108, 97, 119, 121, 101, 114, 32, 226, 128, 148, 32, 68, 97, 118, 105, 100, 32, 82, 101, 97, 100, 101, 32, 75, 67, 32, 226, 128, 148, 32, 109, 97, 100, 101, 32, 116, 104, 101, 32, 102, 111, 108, 108, 111, 119, 105, 110, 103, 32, 111, 98, 115, 101, 114, 118, 97, 116, 105, 111, 110, 46, 32, 226, 128, 156, 84, 104, 101, 114, 101, 32, 97, 114, 101, 32, 108, 111, 97, 100, 115, 32, 111, 102, 32, 115, 105, 116, 101, 115, 32, 110, 111, 119, 32, 119, 104, 101, 114, 101, 32, 65, 73, 32, 119, 105, 108, 108, 32, 119, 114, 105, 116, 101, 32, 97, 32, 103, 114, 105, 101, 118, 97, 110, 99, 101, 32, 111, 114, 32, 100, 114, 97, 102, 116, 32, 97, 110, 32, 69, 84, 49, 32, 99, 108, 97, 105, 109, 44, 226, 128, 157, 32, 104, 101, 32, 115, 97, 105, 100, 32, 111, 110, 32, 116, 104, 101, 32, 115, 104, 111, 119, 46, 32, 226, 128, 156, 73, 32, 102, 101, 101, 108, 32, 97, 32, 108, 111, 116, 32, 111, 102, 32, 115, 121, 109, 112, 97, 116, 104, 121, 32, 102, 111, 114, 32, 116, 104, 101, 32, 101, 109, 112, 108, 111, 121, 109, 101, 110, 116, 32, 116, 114, 105, 98, 117, 110, 97, 108, 32, 98, 101, 99, 97, 117, 115, 101, 32, 116, 104, 101, 121, 32, 97, 114, 101, 32, 116, 121, 112, 105, 99, 97, 108, 108, 121, 32, 103, 101, 116, 116, 105, 110, 103, 32, 108, 105, 116, 105, 103, 97, 110, 116, 115, 32, 105, 110, 32, 112, 101, 114, 115, 111, 110, 32, 97, 110, 100, 32, 116, 104, 101, 32, 102, 105, 114, 115, 116, 32, 116, 97, 115, 107, 32, 116, 104, 101, 121, 32, 104, 97, 118, 101, 32, 116, 111, 32, 100, 111, 32, 97, 116, 32, 97, 110, 32, 101, 97, 114, 108, 121, 32, 115, 116, 97, 103, 101, 32, 105, 110, 32, 108, 105, 116, 105, 103, 97, 116, 105, 111, 110, 32, 105, 115, 32, 117, 110, 112, 105, 99, 107, 32, 119, 104, 97, 116, 32, 116, 104, 101, 32, 108, 101, 103, 97, 108, 32, 105, 115, 115, 117, 101, 115, 32, 97, 114, 101, 46, 226, 128, 157, 10, 10, 69, 115, 115, 101, 110, 116, 105, 97, 108, 108, 121, 44, 32, 68, 97, 118, 105, 100, 32, 119, 97, 115, 32, 109, 97, 107, 105, 110, 103, 32, 116, 104, 101, 32, 112, 111, 105, 110, 116, 32, 116, 104, 97, 116, 32, 101, 109, 112, 108, 111, 121, 109, 101, 110, 116, 32, 116, 114, 105, 98, 117, 110, 97, 108, 115, 32, 97, 114, 101, 32, 110, 111, 119, 32, 115, 119, 97, 109, 112, 101, 100, 32, 98, 121, 32, 118, 101, 114, 98, 111, 115, 101, 32, 97, 112, 112, 108, 105, 99, 97, 116, 105, 111, 110, 115, 32, 116, 104, 97, 116, 32, 104, 97, 118, 101, 32, 98, 101, 101, 110, 32, 99, 114, 101, 97, 116, 101, 100, 32, 98, 121, 32, 65, 73, 44, 32, 102, 114, 111, 109, 32, 108, 105, 116, 105, 103, 97, 110, 116, 115, 32, 119, 104, 111, 32, 109, 105, 103, 104, 116, 32, 111, 116, 104, 101, 114, 119, 105, 115, 101, 32, 110, 111, 116, 32, 104, 97, 118, 101, 32, 104, 97, 100, 32, 116, 104, 101, 32, 116, 105, 109, 101, 32, 111, 114, 32, 114, 101, 115, 111, 117, 114, 99, 101, 115, 32, 116, 111, 32, 109, 97, 107, 101, 32, 97, 32, 99, 108, 97, 105, 109, 46, 32, 84, 104, 105, 115, 32, 105, 115, 32, 103, 111, 111, 100, 44, 32, 111, 110, 32, 111, 110, 101, 32, 108, 101, 118, 101, 108, 32, 226, 128, 148, 32, 119, 101, 32, 119, 97, 110, 116, 32, 112, 101, 111, 112, 108, 101, 32, 116, 111, 32, 110, 111, 116, 32, 98, 101, 32, 115, 116, 105, 102, 108, 101, 100, 32, 105, 110, 32, 109, 97, 107, 105, 110, 103, 32, 117, 110, 102, 97, 105, 114, 32, 100, 105, 115, 109, 105, 115, 115, 97, 108, 32, 99, 108, 97, 105, 109, 115, 32, 226, 128, 148, 32, 98, 117, 116, 32, 98, 97, 100, 44, 32, 105, 110, 32, 97, 110, 111, 116, 104, 101, 114, 32, 119, 97, 121, 46, 32, 84, 104, 101, 114, 101, 32, 105, 115, 32, 97, 108, 114, 101, 97, 100, 121, 32, 97, 32, 104, 117, 103, 101, 32, 98, 97, 99, 107, 108, 111, 103, 32, 105, 110, 32, 116, 101, 114, 109, 115, 32, 111, 102, 32, 100, 101, 97, 108, 105, 110, 103, 32, 119, 105, 116, 104, 32, 116, 104, 101, 115, 101, 32, 99, 108, 97, 105, 109, 115, 44, 32, 97, 110, 100, 32, 105, 116, 226, 128, 153, 115, 32, 113, 117, 105, 116, 101, 32, 99, 108, 101, 97, 114, 32, 116, 104, 97, 116, 32, 97, 108, 108, 32, 112, 97, 114, 116, 105, 101, 115, 32, 97, 114, 101, 32, 97, 100, 118, 97, 110, 116, 97, 103, 101, 100, 32, 98, 121, 32, 97, 32, 113, 117, 105, 99, 107, 32, 114, 101, 115, 111, 108, 117, 116, 105, 111, 110, 46, 32, 89, 111, 117, 32, 99, 97, 110, 32, 117, 115, 101, 32, 65, 73, 32, 116, 111, 32, 99, 114, 101, 97, 116, 101, 32, 99, 108, 97, 105, 109, 115, 44, 32, 97, 110, 100, 32, 119, 104, 105, 108, 101, 32, 121, 111, 117, 32, 109, 105, 103, 104, 116, 32, 40, 101, 118, 101, 110, 116, 117, 97, 108, 108, 121, 41, 32, 98, 101, 32, 97, 98, 108, 101, 32, 116, 111, 32, 117, 115, 101, 32, 65, 73, 32, 116, 111, 32, 116, 114, 105, 97, 103, 101, 32, 99, 108, 97, 105, 109, 115, 44, 32, 116, 104, 101, 32, 102, 105, 110, 97, 108, 32, 100, 101, 99, 105, 115, 105, 111, 110, 32, 105, 110, 32, 99, 97, 115, 101, 115, 32, 108, 105, 107, 101, 32, 116, 104, 105, 115, 32, 104, 97, 115, 32, 116, 111, 32, 98, 101, 32, 109, 97, 100, 101, 32, 98, 121, 32, 97, 32, 104, 117, 109, 97, 110, 46, 32, 65, 110, 100, 32, 116, 104, 97, 116, 32, 109, 101, 97, 110, 115, 32, 116, 104, 101, 32, 115, 121, 115, 116, 101, 109, 32, 105, 115, 32, 103, 101, 116, 116, 105, 110, 103, 32, 103, 117, 109, 109, 101, 100, 32, 117, 112, 46, 10, 10, 73, 116, 32, 114, 101, 109, 105, 110, 100, 101, 100, 32, 109, 101, 32, 111, 102, 32, 97, 32, 112, 105, 101, 99, 101, 32, 73, 32, 114, 101, 97, 100, 32, 97, 116, 32, 116, 104, 101, 32, 119, 101, 101, 107, 101, 110, 100, 32, 97, 98, 111, 117, 116, 32, 104, 111, 119, 32, 65, 73, 32, 119, 97, 115, 32, 98, 101, 105, 110, 103, 32, 117, 115, 101, 100, 32, 98, 121, 32, 78, 73, 77, 66, 89, 115, 32, 40, 78, 111, 116, 45, 73, 110, 45, 77, 121, 45, 66, 97, 99, 107, 121, 97, 114, 100, 101, 114, 115, 44, 32, 102, 111, 114, 32, 116, 104, 111, 115, 101, 32, 108, 101, 115, 115, 32, 116, 101, 114, 109, 105, 110, 97, 108, 108, 121, 32, 111, 110, 108, 105, 110, 101, 41, 32, 116, 111, 32, 103, 114, 105, 110, 100, 32, 116, 104, 101, 32, 112, 108, 97, 110, 110, 105, 110, 103, 32, 115, 121, 115, 116, 101, 109, 32, 116, 111, 32, 97, 32, 104, 97, 108, 116, 46, 32, 84, 104, 101, 32, 71, 117, 97, 114, 100, 105, 97, 110, 32, 110, 111, 116, 101, 100, 32, 97, 32, 110, 101, 119, 32, 115, 101, 114, 118, 105, 99, 101, 44, 32, 99, 97, 108, 108, 101, 100, 32, 79, 98, 106, 101, 99, 116, 111, 114, 32, 40, 73, 32, 119, 111, 110, 226, 128, 153, 116, 32, 108, 105, 110, 107, 32, 116, 111, 32, 105, 116, 44, 32, 97, 115, 32, 105, 116, 32, 109, 97, 107, 101, 115, 32, 109, 101, 32, 113, 117, 101, 97, 115, 121, 41, 44, 32, 119, 104, 105, 99, 104, 32, 117, 115, 101, 115, 32, 65, 73, 32, 116, 111, 32, 115, 99, 97, 110, 32, 112, 108, 97, 110, 110, 105, 110, 103, 32, 97, 112, 112, 108, 105, 99, 97, 116, 105, 111, 110, 115, 32, 97, 110, 100, 32, 102, 105, 110, 100, 32, 116, 104, 101, 32, 104, 105, 103, 104, 101, 115, 116, 32, 105, 109, 112, 97, 99, 116, 32, 111, 98, 106, 101, 99, 116, 105, 111, 110, 46, 32, 84, 104, 101, 32, 115, 101, 114, 118, 105, 99, 101, 32, 119, 97, 115, 32, 100, 101, 115, 105, 103, 110, 101, 100, 32, 98, 121, 32, 97, 32, 75, 101, 110, 116, 32, 99, 111, 117, 112, 108, 101, 32, 119, 104, 111, 44, 32, 97, 99, 99, 111, 114, 100, 105, 110, 103, 32, 116, 111, 32, 84, 104, 101, 32, 71, 117, 97, 114, 100, 105, 97, 110, 44, 32, 100, 101, 115, 105, 103, 110, 101, 100, 32, 116, 104, 101, 32, 115, 121, 115, 116, 101, 109, 32, 226, 128, 156, 97, 102, 116, 101, 114, 32, 101, 115, 116, 105, 109, 97, 116, 105, 110, 103, 32, 116, 104, 101, 121, 32, 115, 112, 101, 110, 116, 32, 104, 117, 110, 100, 114, 101, 100, 115, 32, 111, 102, 32, 104, 111, 117, 114, 115, 32, 97, 116, 116, 101, 109, 112, 116, 105, 110, 103, 32, 116, 111, 32, 110, 97, 118, 105, 103, 97, 116, 101, 32, 116, 104, 101, 32, 112, 108, 97, 110, 110, 105, 110, 103, 32, 112, 114, 111, 99, 101, 115, 115, 32, 119, 104, 101, 110, 32, 116, 104, 101, 121, 32, 111, 112, 112, 111, 115, 101, 100, 32, 112, 108, 97, 110, 115, 32, 116, 111, 32, 99, 111, 110, 118, 101, 114, 116, 32, 97, 32, 98, 117, 105, 108, 100, 105, 110, 103, 32, 110, 101, 97, 114, 32, 116, 104, 101, 105, 114, 32, 104, 111, 109, 101, 32, 105, 110, 116, 111, 32, 97, 32, 109, 111, 115, 113, 117, 101, 46, 226, 128, 157, 32, 84, 104, 101, 32, 112, 108, 97, 110, 110, 105, 110, 103, 32, 115, 121, 115, 116, 101, 109, 32, 104, 101, 114, 101, 32, 105, 110, 32, 116, 104, 101, 32, 85, 75, 32, 105, 115, 32, 97, 108, 114, 101, 97, 100, 121, 32, 105, 110, 32, 100, 105, 115, 97, 114, 114, 97, 121, 44, 32, 119, 105, 116, 104, 32, 104, 111, 117, 115, 101, 98, 117, 105, 108, 100, 105, 110, 103, 32, 103, 111, 97, 108, 115, 32, 114, 111, 117, 116, 105, 110, 101, 108, 121, 32, 115, 116, 121, 109, 105, 101, 100, 32, 98, 121, 32, 108, 111, 99, 97, 108, 32, 112, 114, 111, 116, 101, 115, 116, 115, 32, 97, 110, 100, 32, 105, 110, 102, 114, 97, 115, 116, 114, 117, 99, 116, 117, 114, 101, 32, 112, 114, 111, 106, 101, 99, 116, 115, 32, 100, 105, 115, 114, 117, 112, 116, 101, 100, 32, 98, 121, 32, 102, 97, 105, 114, 108, 121, 32, 108, 111, 119, 45, 103, 114, 97, 100, 101, 32, 99, 111, 110, 99, 101, 114, 110, 115, 32, 40, 106, 117, 115, 116, 32, 71, 111, 111, 103, 108, 101, 32, 226, 128, 156, 72, 83, 50, 32, 98, 97, 116, 32, 116, 117, 110, 110, 101, 108, 226, 128, 157, 32, 105, 102, 32, 121, 111, 117, 32, 119, 97, 110, 116, 32, 116, 111, 32, 117, 110, 100, 101, 114, 115, 116, 97, 110, 100, 32, 109, 111, 114, 101, 32, 97, 98, 111, 117, 116, 32, 115, 99, 108, 101, 114, 111, 116, 105, 99, 32, 66, 114, 105, 116, 97, 105, 110, 41, 46, 32, 83, 108, 111, 119, 105, 110, 103, 32, 116, 104, 101, 32, 112, 108, 97, 110, 110, 105, 110, 103, 32, 112, 114, 111, 99, 101, 115, 115, 32, 102, 117, 114, 116, 104, 101, 114, 32, 109, 97, 107, 101, 115, 32, 105, 116, 32, 101, 118, 101, 110, 32, 108, 101, 115, 115, 32, 100, 101, 115, 105, 114, 97, 98, 108, 101, 32, 116, 111, 32, 99, 111, 110, 115, 116, 114, 117, 99, 116, 111, 114, 115, 32, 97, 110, 100, 32, 105, 110, 118, 101, 115, 116, 111, 114, 115, 44, 32, 121, 101, 116, 32, 65, 73, 32, 104, 97, 115, 32, 98, 101, 101, 110, 32, 97, 102, 102, 111, 114, 100, 101, 100, 32, 116, 104, 101, 32, 112, 111, 119, 101, 114, 32, 116, 111, 32, 102, 108, 111, 111, 100, 32, 116, 104, 101, 32, 112, 108, 97, 110, 110, 105, 110, 103, 32, 115, 121, 115, 116, 101, 109, 32, 119, 105, 116, 104, 32, 118, 101, 120, 97, 116, 105, 111, 117, 115, 32, 111, 98, 106, 101, 99, 116, 105, 111, 110, 115, 32, 116, 104, 97, 116, 44, 32, 117, 108, 116, 105, 109, 97, 116, 101, 108, 121, 44, 32, 104, 97, 118, 101, 32, 116, 111, 32, 98, 101, 32, 97, 110, 97, 108, 121, 115, 101, 100, 32, 98, 121, 32, 97, 32, 104, 117, 109, 97, 110, 46, 32, 65, 116, 32, 116, 104, 101, 32, 109, 111, 109, 101, 110, 116, 44, 32, 116, 104, 101, 32, 114, 117, 108, 101, 115, 32, 97, 114, 101, 32, 115, 105, 109, 112, 108, 101, 58, 32, 97, 108, 108, 32, 111, 98, 106, 101, 99, 116, 105, 111, 110, 115, 32, 104, 97, 118, 101, 32, 116, 111, 32, 103, 111, 32, 116, 104, 114, 111, 117, 103, 104, 32, 116, 104, 101, 32, 115, 97, 109, 101, 32, 112, 114, 111, 99, 101, 115, 115, 101, 115, 44, 32, 114, 101, 103, 97, 114, 100, 108, 101, 115, 115, 32, 111, 102, 32, 119, 104, 101, 116, 104, 101, 114, 32, 116, 104, 101, 121, 226, 128, 153, 114, 101, 32, 99, 114, 101, 97, 116, 101, 100, 32, 98, 121, 32, 104, 117, 109, 97, 110, 115, 32, 111, 114, 32, 65, 73, 46, 10, 10, 79, 118, 101, 114, 32, 105, 110, 32, 116, 104, 101, 32, 106, 111, 98, 32, 109, 97, 114, 107, 101, 116, 44, 32, 116, 104, 101, 32, 70, 105, 110, 97, 110, 99, 105, 97, 108, 32, 84, 105, 109, 101, 115, 32, 112, 114, 111, 118, 105, 100, 101, 100, 32, 115, 111, 109, 101, 32, 105, 110, 102, 111, 114, 109, 97, 116, 105, 111, 110, 32, 111, 110, 32, 116, 104, 101, 32, 117, 115, 101, 32, 111, 102, 32, 76, 76, 77, 115, 32, 105, 110, 32, 106, 111, 98, 32, 97, 112, 112, 108, 105, 99, 97, 116, 105, 111, 110, 115, 44, 32, 115, 111, 109, 101, 116, 104, 105, 110, 103, 32, 116, 104, 97, 116, 32, 105, 115, 32, 110, 111, 119, 32, 117, 98, 105, 113, 117, 105, 116, 111, 117, 115, 46, 32, 84, 104, 101, 32, 100, 97, 116, 97, 32, 112, 114, 111, 118, 105, 100, 101, 100, 32, 97, 32, 102, 97, 105, 114, 108, 121, 32, 112, 114, 101, 100, 105, 99, 116, 97, 98, 108, 101, 32, 99, 111, 110, 99, 108, 117, 115, 105, 111, 110, 58, 32, 102, 111, 114, 32, 119, 101, 97, 107, 32, 99, 97, 110, 100, 105, 100, 97, 116, 101, 115, 44, 32, 117, 115, 105, 110, 103, 32, 67, 104, 97, 116, 71, 80, 84, 32, 116, 111, 32, 119, 114, 105, 116, 101, 32, 97, 32, 99, 111, 118, 101, 114, 32, 108, 101, 116, 116, 101, 114, 32, 111, 102, 102, 101, 114, 101, 100, 32, 97, 32, 115, 105, 103, 110, 105, 102, 105, 99, 97, 110, 116, 32, 105, 109, 112, 114, 111, 118, 101, 109, 101, 110, 116, 32, 116, 111, 32, 101, 109, 112, 108, 111, 121, 109, 101, 110, 116, 32, 99, 104, 97, 110, 99, 101, 115, 46, 32, 70, 111, 114, 32, 115, 116, 114, 111, 110, 103, 101, 114, 32, 99, 97, 110, 100, 105, 100, 97, 116, 101, 115, 44, 32, 105, 116, 32, 100, 101, 99, 114, 101, 97, 115, 101, 100, 32, 112, 114, 111, 115, 112, 101, 99, 116, 115, 46]\n"
     ]
    }
   ],
   "source": [
    "text = '''m not entirely sure why the word ‚Äòslop‚Äô became synonymous with the current wave of AI, but I‚Äôm sure that etymologists (now, or in the distant future) will produce fascinating research on this subject. Slop: it connotes both the bland, formlessness of AI-content (art that looks, simultaneously, like all art and no art) and also has the Dickensian sense of being serve great lashings of gruel, almost without consent. ‚ÄúDo I understand that he asked for more, after he had eaten the supper allotted by the dietary?‚Äù Mr Limbkins inquires, incredulously, after Oliver Twist demands his extra slop. ‚ÄúThat boy will be hung!‚Äù\n",
    "\n",
    "It‚Äôs an apt word, but I have been thinking of late about another a different descriptor for AI content: the TsunamAI.\n",
    "\n",
    "I spent some of this week working (in my 09:00‚Äì17:00 capacity) as a producer on a podcast looking at the Employee Rights Bill, which should shortly become law in the UK. It is a sprawling piece of legislation covering everything from Day One rights to ‚Äòfire and rehire‚Äô practices, and, while interesting, is not the subject of this newsletter. On the episode we made, a leading employment lawyer ‚Äî David Reade KC ‚Äî made the following observation. ‚ÄúThere are loads of sites now where AI will write a grievance or draft an ET1 claim,‚Äù he said on the show. ‚ÄúI feel a lot of sympathy for the employment tribunal because they are typically getting litigants in person and the first task they have to do at an early stage in litigation is unpick what the legal issues are.‚Äù\n",
    "\n",
    "Essentially, David was making the point that employment tribunals are now swamped by verbose applications that have been created by AI, from litigants who might otherwise not have had the time or resources to make a claim. This is good, on one level ‚Äî we want people to not be stifled in making unfair dismissal claims ‚Äî but bad, in another way. There is already a huge backlog in terms of dealing with these claims, and it‚Äôs quite clear that all parties are advantaged by a quick resolution. You can use AI to create claims, and while you might (eventually) be able to use AI to triage claims, the final decision in cases like this has to be made by a human. And that means the system is getting gummed up.\n",
    "\n",
    "It reminded me of a piece I read at the weekend about how AI was being used by NIMBYs (Not-In-My-Backyarders, for those less terminally online) to grind the planning system to a halt. The Guardian noted a new service, called Objector (I won‚Äôt link to it, as it makes me queasy), which uses AI to scan planning applications and find the highest impact objection. The service was designed by a Kent couple who, according to The Guardian, designed the system ‚Äúafter estimating they spent hundreds of hours attempting to navigate the planning process when they opposed plans to convert a building near their home into a mosque.‚Äù The planning system here in the UK is already in disarray, with housebuilding goals routinely stymied by local protests and infrastructure projects disrupted by fairly low-grade concerns (just Google ‚ÄúHS2 bat tunnel‚Äù if you want to understand more about sclerotic Britain). Slowing the planning process further makes it even less desirable to constructors and investors, yet AI has been afforded the power to flood the planning system with vexatious objections that, ultimately, have to be analysed by a human. At the moment, the rules are simple: all objections have to go through the same processes, regardless of whether they‚Äôre created by humans or AI.\n",
    "\n",
    "Over in the job market, the Financial Times provided some information on the use of LLMs in job applications, something that is now ubiquitous. The data provided a fairly predictable conclusion: for weak candidates, using ChatGPT to write a cover letter offered a significant improvement to employment chances. For stronger candidates, it decreased prospects.'''\n",
    "\n",
    "tokens = text.encode(\"utf-8\")\n",
    "tokens = list(map(int, tokens))\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "928d81ab-5611-411c-b347-831a473e9166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(125, (101, 32)), (90, (32, 116)), (73, (116, 104)), (73, (32, 97)), (71, (115, 32)), (67, (116, 32)), (66, (105, 110)), (63, (104, 101)), (49, (97, 110)), (47, (100, 32)), (42, (114, 101)), (41, (101, 114)), (39, (97, 116)), (39, (32, 115)), (38, (101, 115)), (38, (44, 32)), (37, (110, 32)), (37, (32, 119)), (37, (32, 105)), (34, (116, 101)), (34, (110, 103)), (34, (32, 98)), (33, (114, 32)), (33, (32, 111)), (32, (111, 110)), (31, (116, 105)), (31, (103, 32)), (30, (121, 32)), (29, (111, 32)), (29, (110, 116)), (28, (116, 111)), (28, (32, 104)), (28, (32, 99)), (27, (32, 112)), (26, (226, 128)), (26, (105, 115)), (26, (101, 110)), (26, (101, 100)), (25, (115, 116)), (25, (115, 101)), (25, (104, 97)), (24, (111, 114)), (24, (110, 100)), (24, (108, 101)), (24, (97, 108)), (23, (97, 32)), (23, (32, 108)), (21, (118, 101)), (21, (108, 111)), (21, (105, 116)), (21, (100, 101)), (21, (97, 114)), (19, (111, 117)), (19, (109, 101)), (19, (108, 97)), (19, (101, 97)), (19, (32, 109)), (19, (32, 102)), (18, (112, 108)), (17, (114, 111)), (17, (97, 115)), (17, (46, 32)), (17, (32, 100)), (16, (111, 102)), (16, (109, 97)), (16, (104, 105)), (16, (102, 32)), (16, (99, 97)), (15, (117, 115)), (15, (111, 116)), (15, (105, 109)), (15, (105, 99)), (15, (101, 99)), (15, (100, 105)), (14, (112, 114)), (14, (110, 115)), (14, (110, 111)), (14, (108, 121)), (14, (108, 108)), (14, (108, 32)), (14, (105, 111)), (14, (99, 101)), (14, (97, 100)), (13, (108, 105)), (13, (101, 109)), (13, (99, 116)), (13, (99, 111)), (13, (98, 101)), (13, (73, 32)), (13, (32, 117)), (13, (32, 110)), (13, (32, 101)), (13, (32, 65)), (12, (119, 105)), (12, (115, 44)), (12, (110, 101)), (12, (105, 103)), (12, (65, 73)), (12, (32, 226)), (11, (119, 104)), (11, (116, 97)), (11, (115, 115)), (11, (115, 105)), (11, (114, 105)), (11, (109, 112)), (11, (104, 111)), (11, (98, 121)), (11, (97, 105)), (10, (117, 116)), (10, (117, 110)), (10, (111, 119)), (10, (105, 114)), (10, (101, 116)), (10, (97, 118)), (10, (32, 114)), (10, (32, 103)), (10, (32, 84)), (9, (110, 97)), (9, (109, 32)), (9, (107, 101)), (9, (104, 32)), (9, (102, 111)), (9, (99, 108)), (9, (84, 104)), (8, (121, 109)), (8, (119, 97)), (8, (117, 114)), (8, (116, 115)), (8, (115, 121)), (8, (115, 111)), (8, (114, 115)), (8, (114, 100)), (8, (114, 97)), (8, (111, 109)), (8, (110, 110)), (8, (105, 108)), (7, (128, 153)), (7, (118, 105)), (7, (116, 114)), (7, (115, 117)), (7, (114, 116)), (7, (112, 101)), (7, (110, 105)), (7, (109, 111)), (7, (106, 101)), (7, (105, 100)), (7, (103, 101)), (7, (101, 108)), (7, (101, 101)), (7, (98, 117)), (7, (32, 40)), (6, (128, 157)), (6, (128, 156)), (6, (121, 115)), (6, (119, 101)), (6, (119, 32)), (6, (117, 105)), (6, (116, 116)), (6, (115, 108)), (6, (113, 117)), (6, (111, 121)), (6, (111, 115)), (6, (111, 100)), (6, (111, 98)), (6, (110, 99)), (6, (109, 105)), (6, (107, 105)), (6, (107, 32)), (6, (105, 101)), (6, (105, 97)), (6, (104, 117)), (6, (103, 104)), (6, (103, 97)), (6, (99, 114)), (6, (98, 111)), (6, (98, 106)), (6, (97, 107)), (6, (97, 99)), (6, (97, 98)), (5, (121, 44)), (5, (117, 108)), (5, (114, 117)), (5, (112, 112)), (5, (112, 105)), (5, (111, 118)), (5, (111, 112)), (5, (111, 111)), (5, (110, 46)), (5, (109, 115)), (5, (103, 114)), (5, (102, 105)), (5, (101, 121)), (5, (101, 118)), (5, (100, 44)), (5, (99, 107)), (5, (97, 112)), (5, (97, 102)), (5, (41, 32)), (5, (32, 73)), (5, (10, 10)), (4, (157, 32)), (4, (148, 32)), (4, (128, 148)), (4, (119, 111)), (4, (117, 112)), (4, (117, 109)), (4, (117, 101)), (4, (117, 99)), (4, (116, 121)), (4, (116, 117)), (4, (116, 44)), (4, (115, 112)), (4, (115, 104)), (4, (115, 99)), (4, (115, 97)), (4, (114, 118)), (4, (114, 109)), (4, (112, 116)), (4, (112, 111)), (4, (112, 97)), (4, (111, 99)), (4, (105, 102)), (4, (104, 116)), (4, (102, 116)), (4, (102, 97)), (4, (99, 105)), (4, (99, 104)), (4, (98, 108)), (4, (97, 109)), (4, (58, 32)), (4, (32, 79)), (4, (32, 68)), (3, (121, 101)), (3, (121, 41)), (3, (118, 97)), (3, (117, 98)), (3, (117, 97)), (3, (117, 32)), (3, (116, 46)), (3, (115, 46)), (3, (114, 108)), (3, (111, 108)), (3, (111, 103)), (3, (110, 102)), (3, (108, 116)), (3, (108, 115)), (3, (108, 100)), (3, (103, 111)), (3, (103, 110)), (3, (102, 114)), (3, (102, 102)), (3, (102, 101)), (3, (101, 105)), (3, (101, 103)), (3, (101, 44)), (3, (100, 117)), (3, (100, 115)), (3, (100, 97)), (3, (98, 97)), (3, (97, 121)), (3, (97, 119)), (3, (97, 103)), (3, (73, 116)), (3, (68, 97)), (3, (46, 10)), (3, (32, 121)), (3, (32, 113)), (3, (32, 71)), (3, (10, 73)), (2, (157, 10)), (2, (156, 84)), (2, (153, 115)), (2, (153, 32)), (2, (128, 152)), (2, (121, 111)), (2, (119, 114)), (2, (117, 103)), (2, (116, 226)), (2, (115, 107)), (2, (114, 121)), (2, (114, 114)), (2, (114, 107)), (2, (114, 99)), (2, (112, 46)), (2, (111, 107)), (2, (111, 97)), (2, (110, 118)), (2, (110, 107)), (2, (108, 117)), (2, (108, 114)), (2, (108, 44)), (2, (106, 111)), (2, (105, 107)), (2, (105, 98)), (2, (104, 121)), (2, (103, 105)), (2, (102, 117)), (2, (102, 108)), (2, (101, 120)), (2, (101, 119)), (2, (101, 111)), (2, (101, 107)), (2, (101, 46)), (2, (101, 41)), (2, (100, 121)), (2, (100, 114)), (2, (98, 32)), (2, (85, 75)), (2, (83, 108)), (2, (79, 110)), (2, (73, 46)), (2, (73, 44)), (2, (71, 117)), (2, (58, 48)), (2, (48, 48)), (2, (46, 226)), (2, (32, 118)), (2, (32, 106)), (2, (32, 85)), (2, (32, 83)), (2, (32, 82)), (2, (32, 76)), (2, (32, 75)), (2, (32, 70)), (2, (32, 69)), (2, (32, 66)), (1, (156, 97)), (1, (156, 73)), (1, (156, 72)), (1, (156, 68)), (1, (153, 116)), (1, (153, 114)), (1, (153, 109)), (1, (152, 115)), (1, (152, 102)), (1, (147, 49)), (1, (128, 147)), (1, (121, 226)), (1, (121, 116)), (1, (121, 112)), (1, (121, 110)), (1, (121, 97)), (1, (121, 63)), (1, (121, 46)), (1, (121, 45)), (1, (120, 116)), (1, (120, 97)), (1, (119, 121)), (1, (119, 115)), (1, (119, 108)), (1, (119, 46)), (1, (119, 45)), (1, (119, 44)), (1, (116, 108)), (1, (116, 71)), (1, (116, 58)), (1, (116, 45)), (1, (116, 41)), (1, (115, 119)), (1, (115, 114)), (1, (115, 113)), (1, (115, 110)), (1, (115, 109)), (1, (114, 119)), (1, (114, 110)), (1, (114, 98)), (1, (114, 46)), (1, (112, 226)), (1, (112, 58)), (1, (111, 106)), (1, (111, 105)), (1, (111, 44)), (1, (110, 226)), (1, (110, 121)), (1, (110, 113)), (1, (110, 112)), (1, (110, 108)), (1, (110, 58)), (1, (110, 45)), (1, (110, 44)), (1, (110, 41)), (1, (109, 121)), (1, (109, 117)), (1, (109, 109)), (1, (109, 108)), (1, (109, 98)), (1, (109, 65)), (1, (109, 46)), (1, (109, 44)), (1, (108, 226)), (1, (108, 109)), (1, (107, 121)), (1, (107, 115)), (1, (107, 108)), (1, (106, 117)), (1, (105, 118)), (1, (105, 113)), (1, (105, 112)), (1, (104, 114)), (1, (103, 117)), (1, (103, 115)), (1, (103, 108)), (1, (103, 44)), (1, (103, 33)), (1, (101, 226)), (1, (101, 112)), (1, (101, 104)), (1, (101, 98)), (1, (101, 58)), (1, (100, 118)), (1, (100, 111)), (1, (100, 108)), (1, (100, 99)), (1, (99, 117)), (1, (99, 99)), (1, (99, 32)), (1, (98, 115)), (1, (98, 107)), (1, (98, 105)), (1, (97, 117)), (1, (89, 115)), (1, (89, 111)), (1, (84, 119)), (1, (84, 115)), (1, (84, 105)), (1, (84, 49)), (1, (84, 32)), (1, (83, 50)), (1, (82, 105)), (1, (82, 101)), (1, (80, 84)), (1, (79, 118)), (1, (79, 108)), (1, (79, 98)), (1, (78, 111)), (1, (78, 73)), (1, (77, 121)), (1, (77, 115)), (1, (77, 114)), (1, (77, 66)), (1, (76, 105)), (1, (76, 77)), (1, (76, 76)), (1, (75, 101)), (1, (75, 67)), (1, (75, 46)), (1, (75, 32)), (1, (73, 226)), (1, (73, 110)), (1, (73, 77)), (1, (73, 45)), (1, (72, 83)), (1, (71, 111)), (1, (71, 80)), (1, (70, 111)), (1, (70, 105)), (1, (69, 115)), (1, (69, 109)), (1, (69, 84)), (1, (68, 111)), (1, (68, 105)), (1, (67, 104)), (1, (67, 32)), (1, (66, 114)), (1, (66, 105)), (1, (66, 97)), (1, (66, 89)), (1, (65, 116)), (1, (65, 110)), (1, (63, 226)), (1, (57, 58)), (1, (55, 58)), (1, (50, 32)), (1, (49, 55)), (1, (49, 32)), (1, (48, 226)), (1, (48, 57)), (1, (48, 32)), (1, (45, 103)), (1, (45, 99)), (1, (45, 77)), (1, (45, 73)), (1, (45, 66)), (1, (44, 226)), (1, (41, 46)), (1, (41, 44)), (1, (40, 110)), (1, (40, 106)), (1, (40, 105)), (1, (40, 101)), (1, (40, 97)), (1, (40, 78)), (1, (40, 73)), (1, (33, 226)), (1, (32, 89)), (1, (32, 78)), (1, (32, 77)), (1, (32, 67)), (1, (32, 48)), (1, (10, 79)), (1, (10, 69))]\n"
     ]
    }
   ],
   "source": [
    "def get_stats(ids):\n",
    "    counts = {}\n",
    "    for pair in zip(ids, ids[1:]):\n",
    "        counts[pair] = counts.get(pair, 0) + 1\n",
    "    return counts\n",
    "stats = get_stats(tokens)\n",
    "print(sorted(((v, k ) for k, v in stats.items()), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8caa576a-abb2-4b74-8f59-ceba43b9689c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' ', 't')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(32), chr(116)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1f15c1aa-0ba7-43ed-9f12-c44fd38dc38b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merging (101, 32) into a new token 256\n",
      "merging (32, 116) into a new token 257\n",
      "merging (105, 110) into a new token 258\n",
      "merging (115, 32) into a new token 259\n",
      "merging (116, 32) into a new token 260\n",
      "merging (257, 104) into a new token 261\n",
      "merging (97, 110) into a new token 262\n",
      "merging (101, 114) into a new token 263\n",
      "merging (100, 32) into a new token 264\n",
      "merging (44, 32) into a new token 265\n",
      "merging (261, 256) into a new token 266\n",
      "merging (111, 110) into a new token 267\n",
      "merging (258, 103) into a new token 268\n",
      "merging (121, 32) into a new token 269\n",
      "merging (97, 116) into a new token 270\n",
      "merging (101, 115) into a new token 271\n",
      "merging (111, 32) into a new token 272\n",
      "merging (101, 110) into a new token 273\n",
      "merging (226, 128) into a new token 274\n",
      "merging (111, 114) into a new token 275\n",
      "merging (268, 32) into a new token 276\n",
      "merging (97, 108) into a new token 277\n",
      "merging (97, 32) into a new token 278\n",
      "merging (108, 111) into a new token 279\n",
      "merging (97, 114) into a new token 280\n",
      "merging (101, 264) into a new token 281\n",
      "merging (111, 117) into a new token 282\n",
      "merging (116, 104) into a new token 283\n",
      "merging (114, 101) into a new token 284\n",
      "merging (46, 32) into a new token 285\n",
      "merging (116, 105) into a new token 286\n",
      "merging (111, 102) into a new token 287\n",
      "merging (101, 99) into a new token 288\n",
      "merging (115, 116) into a new token 289\n",
      "merging (257, 272) into a new token 290\n",
      "merging (32, 119) into a new token 291\n",
      "merging (105, 259) into a new token 292\n",
      "merging (112, 114) into a new token 293\n",
      "merging (105, 99) into a new token 294\n",
      "merging (263, 32) into a new token 295\n"
     ]
    }
   ],
   "source": [
    "def get_stats(idx):\n",
    "    counts = {}\n",
    "    for pair in zip(idx, idx[1:]):\n",
    "        counts[pair] = counts.get(pair, 0) + 1\n",
    "    return counts\n",
    "\n",
    "def merge(ids, pair, idx):\n",
    "    newids = []\n",
    "    i = 0\n",
    "    while(i < len(ids)):\n",
    "        if i < len(ids) - 1 and ids[i] == pair[0] and ids[i+1] == pair[1]:\n",
    "            newids.append(idx)\n",
    "            i += 2\n",
    "        else:\n",
    "            newids.append(ids[i])\n",
    "            i += 1\n",
    "    return newids\n",
    "\n",
    "vocab_size = 296 # hyperparameter can be tuned\n",
    "num_merges = vocab_size - 256\n",
    "ids = list(tokens)\n",
    "\n",
    "merges = {}\n",
    "for i in range(num_merges):\n",
    "    stats = get_stats(ids)\n",
    "    pair = max(stats, key=stats.get)\n",
    "    idx = 256 + i\n",
    "    print(f\"merging {pair} into a new token {idx}\")\n",
    "    ids = merge(ids, pair, idx)\n",
    "    merges[pair] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7d2960ce-265d-4db0-b096-b6ba155e9d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token length:  3912\n",
      "ids length:  2678\n",
      "compression ratio : 1.46\n"
     ]
    }
   ],
   "source": [
    "print(\"token length: \" , len(tokens))\n",
    "print(\"ids length: \", len(ids))\n",
    "print(f\"compression ratio : {len(tokens)  / len(ids):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "58021a8b-c3e1-4ab7-89c5-d59a1b2b1323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0001\n"
     ]
    }
   ],
   "source": [
    "vocab = {idx: bytes([idx]) for idx in range(256)}\n",
    "\n",
    "for (p0, p1), idx in merges.items():\n",
    "    vocab[idx] = vocab[p0] + vocab[p1]\n",
    "    \n",
    "def decode(ids):\n",
    "    # given ids (list of integers), return python string\n",
    "    tokens = b\"\".join(vocab[idx] for idx in ids)\n",
    "    text = tokens.decode(\"utf-8\", errors=\"replace\")\n",
    "    return text\n",
    "\n",
    "print(decode([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "accc7b4c-4fb7-470d-9f5a-cac6d23fb578",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(101, 32): 256,\n",
       " (32, 116): 257,\n",
       " (105, 110): 258,\n",
       " (115, 32): 259,\n",
       " (116, 32): 260,\n",
       " (257, 104): 261,\n",
       " (97, 110): 262,\n",
       " (101, 114): 263,\n",
       " (100, 32): 264,\n",
       " (44, 32): 265,\n",
       " (261, 256): 266,\n",
       " (111, 110): 267,\n",
       " (258, 103): 268,\n",
       " (121, 32): 269,\n",
       " (97, 116): 270,\n",
       " (101, 115): 271,\n",
       " (111, 32): 272,\n",
       " (101, 110): 273,\n",
       " (226, 128): 274,\n",
       " (111, 114): 275,\n",
       " (268, 32): 276,\n",
       " (97, 108): 277,\n",
       " (97, 32): 278,\n",
       " (108, 111): 279,\n",
       " (97, 114): 280,\n",
       " (101, 264): 281,\n",
       " (111, 117): 282,\n",
       " (116, 104): 283,\n",
       " (114, 101): 284,\n",
       " (46, 32): 285,\n",
       " (116, 105): 286,\n",
       " (111, 102): 287,\n",
       " (101, 99): 288,\n",
       " (115, 116): 289,\n",
       " (257, 272): 290,\n",
       " (32, 119): 291,\n",
       " (105, 259): 292,\n",
       " (112, 114): 293,\n",
       " (105, 99): 294,\n",
       " (263, 32): 295}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fc0cf3bf-0099-444e-89a0-335aa97c3c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[104, 101, 108, 108, 272, 119, 275, 108, 100, 33]\n"
     ]
    }
   ],
   "source": [
    "def encode(text):\n",
    "    tokens = list(text.encode(\"utf-8\"))\n",
    "    while True:\n",
    "        stats = get_stats(tokens)\n",
    "        pair = min(stats, key = lambda p: merges.get(p, float(\"inf\")))\n",
    "        if pair not in merges:\n",
    "            break # nothing else can be merged\n",
    "        idx = merges[pair]\n",
    "        tokens = merge(tokens, pair, idx)\n",
    "    return tokens\n",
    "print(encode(\"hello world!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f8252aa5-3ce7-4de0-a4eb-3254e455055c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi this is great\n"
     ]
    }
   ],
   "source": [
    "print(decode(encode(\"hi this is great\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c15e380-d0ec-44b4-8c8c-701ed6d47afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = decode("
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
